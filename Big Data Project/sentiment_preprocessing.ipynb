{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The sentiment analysis code was taken from https://www.geeksforgeeks.org/twitter-sentiment-analysis-using-python/\n",
    "and modified to analyze our pre-collected twitter data.\n",
    "\"\"\"\n",
    "\n",
    "import re \n",
    "import tweepy \n",
    "from tweepy import OAuthHandler \n",
    "from textblob import TextBlob \n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "  \n",
    "def clean_tweet(tweet): \n",
    "    ''' \n",
    "    Utility function to clean tweet text by removing links, special characters \n",
    "    using simple regex statements. \n",
    "    '''\n",
    "    return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split()) \n",
    "\n",
    "def get_tweet_sentiment(tweet): \n",
    "    ''' \n",
    "    Utility function to classify sentiment of passed tweet \n",
    "    using textblob's sentiment method \n",
    "    '''\n",
    "    # create TextBlob object of passed tweet text \n",
    "    analysis = TextBlob(clean_tweet(tweet)) \n",
    "    # set sentiment \n",
    "    if analysis.sentiment.polarity > 0: \n",
    "        return 'positive'\n",
    "    elif analysis.sentiment.polarity == 0: \n",
    "        return 'neutral'\n",
    "    else: \n",
    "        return 'negative'\n",
    "\n",
    "def get_sentiment_tweets(filename): \n",
    "    ''' \n",
    "    Main function to fetch tweets and parse them. \n",
    "    '''\n",
    "    # empty list to store parsed tweets \n",
    "    tweets = [] \n",
    "    tweets_text = []\n",
    "\n",
    "    try: \n",
    "        with open(filename) as f:\n",
    "            fetched_tweets = [json.loads(line) for line in f]\n",
    "            \n",
    "        for tweet in fetched_tweets: \n",
    "            \n",
    "            if 'text' not in tweet:\n",
    "                print('no text field in:\\n', tweet)\n",
    "            else:\n",
    "                tweet['sentiment'] = get_tweet_sentiment(tweet['text'])\n",
    "            \n",
    "                # this sentiment analysis only works on english tweets. Also throw out direct retweets\n",
    "                if tweet['lang'] == 'en' and (tweet['retweet_count'] == 0 or tweet['text'] not in tweets_text):\n",
    "                    tweets.append(tweet) \n",
    "                    tweets_text.append(tweet['text'])\n",
    "\n",
    "        return tweets \n",
    "\n",
    "    except tweepy.TweepError as e: \n",
    "        # print error (if any) \n",
    "        print(\"Error : \" + str(e)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# preprocessing search api data\n",
    "\n",
    "print(\"cspan SUMMARY:\\n\") # change this and run for each of the keywords\n",
    "\n",
    "m = '02'\n",
    "d = 20 # should be 15 for CNN, FoxNews, and MSNBC, but 20 for cspan and NPR\n",
    "\n",
    "outFile = open(\"sentiment_processed_data/search/cspan_sentiment.json\", 'w') # change this filename for each keyword\n",
    "\n",
    "total_pos = 0\n",
    "total_neg = 0\n",
    "total = 0\n",
    "\n",
    "for i in range(20): # should be 25 for CNN, FoxNews, and MSNBC, but 20 for cspan and NPR\n",
    "    filename = \"raw_data/cspan/cspan_search_2020-\" + m + \"-{:02d}\".format(d) + '.json' # change this filename for each keyword\n",
    "    d = d + 1\n",
    "    if m == '02' and d == 30:\n",
    "        m = '03'\n",
    "        d = 1\n",
    "    \n",
    "    this_file_pos = 0\n",
    "    this_file_neg = 0\n",
    "    \n",
    "    sentiment_tweets = get_sentiment_tweets(filename)\n",
    "    \n",
    "    for twt in sentiment_tweets:\n",
    "        json.dump(twt, outFile)\n",
    "        outFile.write('\\n')\n",
    "        \n",
    "        if twt['sentiment'] == 'positive':\n",
    "            this_file_pos += 1\n",
    "        elif twt['sentiment'] == 'negative':\n",
    "            this_file_neg += 1\n",
    "        \n",
    "        \n",
    "    print(\"file:\", filename)\n",
    "    print(\"valid tweets:\", len(sentiment_tweets))\n",
    "    print(\"positive tweets:\", this_file_pos)\n",
    "    print(\"negative tweets:\", this_file_neg)\n",
    "    print(\"neutral tweets:\", len(sentiment_tweets) - this_file_pos - this_file_neg)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    total += len(sentiment_tweets)\n",
    "    total_pos += this_file_pos\n",
    "    total_neg += this_file_neg\n",
    "\n",
    "    \n",
    "    \n",
    "outFile.close()\n",
    "print(\"FINAL RESULTS\")\n",
    "print(\"valid tweets:\", total)\n",
    "print(\"positive tweets:\", total_pos, \"=\", total_pos/total*100, '%')\n",
    "print(\"negative tweets:\", total_neg, \"=\", total_neg/total*100, '%')\n",
    "print(\"neutral tweets:\", total-total_pos-total_neg, \"=\", (total-total_pos-total_neg)/total*100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test *_sentiment.json was written correctly to the file\n",
    "\n",
    "with open('cspan_sentiment.json') as f: # change this filename for each of the keywords\n",
    "    tweets = [json.loads(line) for line in f]\n",
    "    data = pd.DataFrame(columns=['user','sentiment', 'text']);\n",
    "    for twt in tweets:\n",
    "        data = data.append({'sentiment': twt['sentiment'], 'text': twt['text'], 'user': str(twt['user']['screen_name'])}, ignore_index = True)\n",
    "\n",
    "print(len(data))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# preprocess streaming data\n",
    "print(\"STREAMING SUMMARY:\\n\")\n",
    "\n",
    "files = [\"streaming_2020-03-03-0930.json\", \"streaming_2020-03-03-1300.json\", \"streaming_2020-03-03-1700.json\", \"streaming_2020-03-03-2230.json\"]\n",
    "keywords = ['CNN', 'FoxNews', 'MSNBC', 'NPR', 'cspan']\n",
    "\n",
    "tweet_lists = [[], [], [], [], []]\n",
    "\n",
    "for filename in files:\n",
    "    \n",
    "    sentiment_tweets = get_sentiment_tweets(\"raw_data/streaming/\" + filename)\n",
    "    \n",
    "    for twt in sentiment_tweets:\n",
    "        for i in range(5):\n",
    "            if keywords[i] in twt['text']:\n",
    "                tweet_lists[i].append(twt)\n",
    "\n",
    "\n",
    "total_tweets = 0\n",
    "for i in range(5):\n",
    "    total_tweets += len(tweet_lists[i])\n",
    "\n",
    "                \n",
    "# now write all CNN to a file, all FoxNews to a different file, etc\n",
    "for i in range(5):\n",
    "    outFile = open(\"sentiment_processed_data/streaming/\" + keywords[i] + \"_streaming_sentiment.json\", 'w')\n",
    "    \n",
    "    this_keyword_pos = 0\n",
    "    this_keyword_neg = 0\n",
    "\n",
    "    for twt in tweet_lists[i]:\n",
    "        json.dump(twt, outFile)\n",
    "        outFile.write('\\n')\n",
    "        \n",
    "        if twt['sentiment'] == 'positive':\n",
    "            this_keyword_pos += 1\n",
    "        elif twt['sentiment'] == 'negative':\n",
    "            this_keyword_neg += 1\n",
    "            \n",
    "    outFile.close()\n",
    "        \n",
    "    print(keywords[i])\n",
    "    print(\"valid tweets:\", len(tweet_lists[i]), \"(\"+str(len(tweet_lists[i])/total_tweets*100)+\"% of total)\")\n",
    "    print(\"positive tweets:\", this_keyword_pos, \"(\"+str(this_keyword_pos/len(tweet_lists[i])*100)+\"%)\")\n",
    "    print(\"negative tweets:\", this_keyword_neg, \"(\"+str(this_keyword_neg/len(tweet_lists[i])*100)+\"%)\")\n",
    "    print(\"neutral tweets:\", len(tweet_lists[i])-this_keyword_pos-this_keyword_neg, \"(\"+str((len(tweet_lists[i])-this_keyword_pos-this_keyword_neg)/len(tweet_lists[i])*100)+\"%)\")\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
