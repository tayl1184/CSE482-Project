{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy import API\n",
    "import json\n",
    "\n",
    "import time\n",
    "from tweepy.streaming import StreamListener\n",
    "from tweepy import Stream\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "C_KEY = ''\n",
    "C_SECRET = ''\n",
    "A_TOKEN_KEY = ''\n",
    "A_TOKEN_SECRET = ''\n",
    "\n",
    "auth = tweepy.OAuthHandler(C_KEY, C_SECRET)\n",
    "auth.set_access_token(A_TOKEN_KEY, A_TOKEN_SECRET)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = ['CNN', 'FoxNews', 'MSNBC', 'NPR', 'cspan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('CNN', 100), ('FoxNews', 100), ('MSNBC', 100), ('NPR', 100), ('cspan', 100)]\n"
     ]
    }
   ],
   "source": [
    "# collect search data\n",
    "\n",
    "filename = 'search_2020-03-10.json' # update this each time\n",
    "results = []\n",
    "for keyword in keywords:\n",
    "    keyword_filename = keyword +\"/\" + keyword + \"_\" + filename\n",
    "    outFile = open(keyword_filename, 'w')\n",
    "    \n",
    "    posts = api.search(q=keyword,count=1000, result_type='mixed', until='2020-03-11') # update 'until' each time\n",
    "    \n",
    "    count = 0\n",
    "    for tweet in posts:\n",
    "        outFile.write(json.dumps(tweet._json))\n",
    "        outFile.write('\\n')\n",
    "        count += 1\n",
    "    results.append((keyword, count))\n",
    "        \n",
    "    outFile.close()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# check that data was collected correctly\n",
    "\n",
    "with open('CNN/CNN' + \"_\" + filename) as f:\n",
    "    tweets = [json.loads(line) for line in f]\n",
    "    data = pd.DataFrame(columns=['user','id', 'date']);\n",
    "    for twt in tweets:\n",
    "        data = data.append({'id': twt['id'], 'date': twt['created_at'], 'user': str(twt['user']['screen_name'])}, ignore_index = True)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class for collecting streaming data\n",
    "\n",
    "class MyListener(StreamListener):\n",
    "\n",
    "    def __init__(self, filename, time_limit=10):\n",
    "        self.start_time = time.time()\n",
    "        self.limit = time_limit\n",
    "        self.outFile = open(filename, 'w')\n",
    "        super(MyListener, self).__init__()\n",
    "    \n",
    "    def on_data(self, data):\n",
    "        if (time.time() - self.start_time) < self.limit:\n",
    "            self.outFile.write(data.strip())     \n",
    "            self.outFile.write('\\n') \n",
    "            return True\n",
    "        else:\n",
    "            self.outFile.close()\n",
    "            return False\n",
    "\n",
    "    def on_error(self, status):\n",
    "        print(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect streaming data\n",
    "\n",
    "filename = \"streaming_2020-03-03-2230.json\"\n",
    "duration = 60 * 20\n",
    "myStream = Stream(auth, MyListener(filename, time_limit=duration))\n",
    "myStream.filter(track=keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check that streaming data was collected correctly\n",
    "\n",
    "with open(filename) as f:\n",
    "    tweets = [json.loads(line) for line in f]\n",
    "    data = pd.DataFrame(columns=['user','text', 'date']);\n",
    "    for twt in tweets:\n",
    "        try:\n",
    "            data = data.append({'text': twt['text'], 'date': twt['created_at'], 'user': str(twt['user']['screen_name'])}, ignore_index = True)\n",
    "        except KeyError:\n",
    "            KeyError"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
